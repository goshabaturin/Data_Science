{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта «Определение перспективного тарифа для телефонной компании»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — она уже сделана.\n",
    "\n",
    "Необходимо построить модель с максимально большим значением *accuracy*, но не меньше 0.75. Проверить *accuracy* на тестовой выборке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем все необходимые библиотеки\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# модель логистической регрессии, но она нам пригодится, потому что у нас задача классификации, а не прогноза конкретного значения\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# модель дерева решений\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# модель случайного леса\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# метод для разделения выборки на тренировочную и валидационную\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# метод для расчета mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# метод для расчета accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# библиотека для выгрузки модели в файл\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на исходные данные\n",
    "#df = pd.read_csv('https://code.s3.yandex.net/datasets/users_behavior.csv')\n",
    "#df = pd.read_csv('https://code.s3.yandex.net/datasets/users_behavior.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, исходные данные уже преведены к задаче классификации. Если в поле \"is_ultra\" стоит 0, то означает что тариф ***не*** Ultra, а значит что он Smart, если стоит 1, то тариф Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Исходные данные приведены к задачи классификации. \n",
    "Мы имеем выбоку клиентов, которые уже перешли на один из двух тарифов и должны научиться оперелять по косвенным признакам, какой из тарифов выбрал абонент. В дальнейшем мы хотим применить эту модель, чтобы предлагать старым клиентам один из двух тарифов наиболее подходящий, взамен архивного. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобъем данные на тренировочную, тестовую и валидационную выборки\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "\n",
    "# сначала выделим тестовую выборку, которая должна быть 20%\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "\n",
    "# теперь оставшиеся 80% разобъем на тренировочную и валидационную выборку, \n",
    "# так, чтоб тренировочная была 60% от датасета, а валидационная 20% от датасета\n",
    "# другими словами, 75% и 25% от тех 80% что остались\n",
    "\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.25, random_state=12345)\n",
    "\n",
    "\n",
    "# обозначим зависимые и независимые переменные для тренировочной, тестовой и валидационной выборок\n",
    "\n",
    "features_train = df_train.drop('is_ultra',axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_test = df_test.drop('is_ultra',axis=1)\n",
    "target_test = df_test['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop('is_ultra',axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать модель дерева решений, модель случайного леса и модель логистической регрессии. В свою очередь, у модели случайного леса могут быть различные гиперпараметры, такие как глубина (max_depth) и количество деревьев (n_estimators).\n",
    "\n",
    "Чтобы не плодить однотипный код, оформим в функицию процесс обучения модели и расчета ее accuracy. Функция будет получать на вход модель, тестовые и валидационные фоеймы и будет возвращать accuracy тренировочной и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model, features_train, features_valid, target_train, target_valid):\n",
    "    # обучим модель\n",
    "    model.fit(features_train,target_train)\n",
    "\n",
    "    # построим предсказания модели\n",
    "    predictions_train = model.predict(features_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    \n",
    "\n",
    "    # посмотрим, насколько точна модель\n",
    "    \n",
    "    return accuracy_score(target_train, predictions_train), accuracy_score(target_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, функцию написали. Теперь посмотрим на модель дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели\n",
      "train: 1.0\n",
      "valid: 0.7122861586314152\n"
     ]
    }
   ],
   "source": [
    "# объявим модель дерева решений\n",
    "model_tree = DecisionTreeRegressor(random_state=12345)\n",
    "\n",
    "# и вызовем функцию в которой обучим модель и посмотрим accuracy \n",
    "accuracy_train, accuracy_valid = models(model_tree, features_train, features_valid, target_train, target_valid)\n",
    "\n",
    "print('Accuracy модели')\n",
    "print('train:',accuracy_train)\n",
    "print('valid:',accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень то и хорошо. Дерево решений отлично определяет где какой тариф на тренировочной выборке (еще-бы, вызубрил!), но вот на \n",
    "валидационной выборке точность такая себе - всего 71%. Не очень результат.\n",
    "\n",
    "Посмотрим на модели случайного леса с разными гиперпарраметрами глубины (max_depth) и разным количеством деревьев (n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим словарь, в котором ключами будут значения глубины дерева и количества деревьев в лесу,\n",
    "# а значениями - accuracy валидационной выборки\n",
    "results={}\n",
    "\n",
    "# в цикле переберем различные комбинации глубины дерева и количества деревьев и запишем соответствующие accaracy валидационной выборки в словарь\n",
    "for depth in range(1,20,1):\n",
    "    for estim in range(1,20,1):\n",
    "        # объявим модель\n",
    "        model_forest = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estim, min_samples_split=5)\n",
    "        \n",
    "        # воспользуемся ранее описанной функцией\n",
    "        accuracy_train, accuracy_valid = models(model_forest, features_train, features_valid, target_train, target_valid)\n",
    "        \n",
    "        # создадим ключ для словаря\n",
    "        keys = 'depth='+str(depth)+\", estim=\"+str(estim)\n",
    "        \n",
    "        # создадим значение для ключа\n",
    "        val = accuracy_valid \n",
    "        \n",
    "        # запишем пару \"ключ: значение\" в словарь\n",
    "        results.update({str(keys):val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная accuracy модели случайного леса достигается при depth=14, estim=3\n",
      "и точность модели на валидационных данных составляет 80.72%\n"
     ]
    }
   ],
   "source": [
    "# посмотрим при каком ключе у нас получилось максимальное значение \n",
    "key_max_accuracy = max(results, key=results.get)\n",
    "\n",
    "print(\"Максимальная accuracy модели случайного леса достигается при\",key_max_accuracy)\n",
    "print(\"и точность модели на валидационных данных составляет {:.2%}\".format(results.get(key_max_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтож, уже лучше. При лесе из 3х деревьев с глубиной дерева не более 14 уровней точность предсказаний составляет уже 80%. Обучим модель случайного леса на этих параметрах и в дальнейшем проверим модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state=12345, max_depth=14, n_estimators=3, min_samples_split=5)\n",
    "model_forest.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса мы обучили на тестовой выборке и подобрали ей параметры на валидационной выборке. Теперь ее можно отложить, к ней мы вернемся позже, чтобы посмотреть на ее точность на тестовой выборке (спойлер: 78%). А пока посмотрим, имеет ли смысл использовать модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6967340590979783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_logistic_regression = LogisticRegression()\n",
    "model_logistic_regression.fit(features_train,target_train)\n",
    "predictions_valid_logistic_regression = model_logistic_regression.predict(features_valid)\n",
    "print(accuracy_score(target_valid,predictions_valid_logistic_regression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, на валидационных данных модель логисчтической регрессии показывает самую малую точность, всео 69.7%. \n",
    "\n",
    "*N.B.: получили сообщение, что в следующей версии библиотеки sklearn нам нужно будет указывать параметр max_iter в явном виде, при использовании логистической регрессии*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Среди моделей логистической регрессии, дерева решений и случайного леса мы выбрали модель, которая илучшим образом классифицирует данные на тренировочной и валидационной выборках. Это модель случайного леса и для нее мы подобрали такие параметры глубины деревьев и количества деревьев, при которых достигается максимальная точность на валидационной выборке.\n",
    "\n",
    "Теперь самое время проверить настроенную нами модель случайного леса на тестовой выборке и узнать, на сколько она хороша."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы выбрали, настроили и обучили модель случайного леса. Нам остается лишь сделать предсказания и посмотреть на их точность. Для этого используем тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели случайного леса на тестовой выборке составляет 78.23%\n"
     ]
    }
   ],
   "source": [
    "predictions_test_forest = model_forest.predict(features_test)\n",
    "print(\"Точность модели случайного леса на тестовой выборке составляет {:.2%}\".format(accuracy_score(target_test, predictions_test_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воу! Не так уж и ужастно. Точность на тестовой выборке лучше чем на тренировочной выборке у модели дерева решений и модели логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка адекватности модели будет заключаться в проверке качества модели в сравнении с константной моделью. Если модель плохо предсказывает заранее известные нам константы, то модель будем считать неадекватной.\n",
    "Предскажем для всего теста метку наибольшего класса, посчитаем accuracy и сравним с accuracy нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего абонентов на тарифе Ultra: 985\n",
      "Всего абонентов на тарифе Smart: 2229\n"
     ]
    }
   ],
   "source": [
    "# посмотрим количество значений в каждом из классов\n",
    "\n",
    "users_Smart=df[df['is_ultra']==0]['is_ultra'].count()\n",
    "users_Ultra = df[df['is_ultra']==1]['is_ultra'].count()\n",
    "\n",
    "print(\"Всего абонентов на тарифе Ultra:\",total_Ultra)\n",
    "print(\"Всего абонентов на тарифе Smart:\",total_Smart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, значит проверку адекватности модели будем производить на выборке из пользователей тарифа Smart, это и есть метка наибольшего класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели случайного леса в проверке на адекватность 94.12%\n"
     ]
    }
   ],
   "source": [
    "# определим зависимые и независимые переменные\n",
    "features_sanity_check = df.query('is_ultra==0').drop('is_ultra',axis=1)\n",
    "target_sanity_check = df.query('is_ultra==0')['is_ultra']\n",
    "\n",
    "# предскажем значения зависимых переменных\n",
    "predictions_sanity_check = model_forest.predict(features_sanity_check)\n",
    "\n",
    "# посчитаем и выведем accuracy\n",
    "accuracy_sanity_check = accuracy_score(target_sanity_check, predictions_sanity_check)\n",
    "print(\"Точность модели случайного леса в проверке на адекватность {:.2%}\".format(accuracy_sanity_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**вывод**\n",
    "\n",
    "Выбранная модель достаточно точно предсказывает значения и может считаться адекватной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод\n",
    "\n",
    "Моделью для задачи классификация является модель случайного леса с деревьями не глубже 14 уровней и количество деревьев в лесу - 3 штуки. Эта модель адекватна и предсказывает с точностью 78.23% на тестовой выборке. Возможно, она могла бы и точнее (поработав с параметрами глубины и количества деревьев), но в рамках проекта нам достаточно точности и в 75%. Модель выгружена в файл 'model.joblib'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_forest,'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
